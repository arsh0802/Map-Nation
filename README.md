# MAP-NATION – AI-Powered Personalized Learning Roadmap Generator

## Project Purpose

**MAP-NATION** is an advanced platform that leverages GenAI to help users achieve their learning goals efficiently. It generates **personalized, time-bound learning roadmaps** and quizzes, precisely tailored to what each user wants to learn and the time they have available. Whether you're mastering a new skill, preparing for exams, or exploring new topics, MAP-NATION provides a clear, actionable path powered by state-of-the-art AI.

---

## Key Features & Architecture

- **AI Roadmap Generation:**  
  Users receive a custom learning roadmap, generated by GenAI (Google Gemini/OpenAI) and custom logic, based on their goals, available time, and preferred topics. The backend endpoint directly calls the Gemini API utility and saves the generated roadmap to the database for each user.

- **Time-Bound Precision:**  
  The system creates learning plans that fit within the user's specified duration and daily learning time, ensuring realistic and achievable progress.

- **Quiz Generation & Evaluation:**  
  AI-generated quizzes help users test their knowledge, with instant feedback and analytics.

- **Progress & Session Tracking:**  
  All user progress, quiz results, and roadmap completions are tracked for deep insights and motivation.

- **Scalable, Modular Design:**  
  Built with Node.js, Express, React, and Python, the system is ready for high concurrency and easy expansion.

- **Performance Optimized:**  
  Implements load balancing, asynchronous processing, and efficient data pipelines for a fast, responsive user experience.

---

## System Workflow

1. **User specifies learning goals, topics, duration, and daily study time.**
2. **AI Roadmap Generation:**  
   The backend (Node.js/Express) calls the Gemini API utility to generate a personalized, time-bound learning roadmap, which is saved to the database and returned to the user.
3. **User receives a detailed, step-by-step roadmap** tailored to their needs.
4. **Quiz Generation:**  
   Users can generate quizzes on any topic to test their understanding.
5. **Quiz Evaluation:**  
   The system evaluates answers and provides instant feedback and analytics.
6. **Progress Tracking:**  
   All sessions, quiz results, and roadmap completions are stored in MongoDB for analytics and user motivation.
7. **Scalable Processing:**  
   Heavy AI/model tasks are handled asynchronously, with support for multiple backend workers and load balancing.
8. **(Optional) Model Training:**  
   The system can be extended to train custom models using distributed data pipelines.

---

## Why These Technologies? (Advanced Justification)

| Component         | What It Does                        | Why Used / Performance Benefit                                  |
|-------------------|-------------------------------------|-----------------------------------------------------------------|
| **Gemini/OpenAI** | Generates roadmaps, quizzes, feedback | State-of-the-art GenAI, context-aware, scalable, fast           |
| **Node.js/Express**| API server, orchestrates workflow  | Non-blocking, event-driven, ideal for high-concurrency APIs     |
| **React**         | Frontend UI                         | Fast, interactive, component-based user experience              |
| **Python (ML)**   | Custom AI/ML logic, data processing | Efficient, flexible for AI/ML tasks, easy integration           |
| **MongoDB**       | Stores all data                     | NoSQL, horizontally scalable, handles large analytics datasets  |
| **Multer**        | Handles file uploads (if needed)    | Streams files, prevents memory bottlenecks                      |
| **Nginx Load Balancer** | Distributes API traffic        | Ensures high availability and low latency under heavy load      |
| **Async Processing**| Handles heavy tasks in background | Keeps API responses fast, user never waits for analysis         |

---

## Performance & Scalability

- **Nginx Load Balancing:**  
  The system is designed to run behind an Nginx load balancer, distributing incoming API requests across multiple Node.js and Python workers for high availability and low latency.

- **Horizontal Scalability:**  
  Both the Node.js API and Python AI services can be scaled horizontally (multiple servers/containers). MongoDB supports sharding and replica sets for data reliability.

- **Asynchronous Processing:**  
  All heavy AI/model tasks are handled asynchronously, so the server can process multiple requests in parallel.

- **Optimized Data Pipelines:**  
  Data is streamed and processed in chunks, preventing memory overload and ensuring fast feedback.

- **Caching & Rate Limiting:**  
  Frequently requested roadmaps/quizzes can be cached (e.g., Redis), and rate limiting prevents abuse.

---

## AI/GenAI Integration

- **How it works:**  
  When a user requests a roadmap, the backend sends the request to the Gemini API utility, which generates a personalized, context-aware roadmap. The roadmap is saved to the database and returned to the user in real-time. Quiz generation and evaluation are also powered by GenAI.

- **Why GenAI?**  
  GenAI models (like Gemini and OpenAI) provide ultra-fast, high-quality, and context-rich content generation, making learning plans and quizzes truly personalized.

- **Integration:**  
  The Node.js backend orchestrates all AI calls, combines results, and manages user sessions and analytics.

---

## Model Training & Dataset Details

- **Roadmap Generation:**  
  - **Datasets:**  
    - [Open Syllabus Project](https://opensyllabus.org/) – for curriculum/roadmap inspiration
    - [Curriculum Dataset (Kaggle)](https://www.kaggle.com/datasets/andrewmvd/curriculum-dataset)
    - [Awesome Learning Paths](https://github.com/tuvtran/project-based-learning)
  - **Training Process:**  
    - Data is preprocessed and used to fine-tune or prompt GenAI models for roadmap generation.
    - Custom logic ensures plans are time-bound and goal-specific.

- **Quiz Generation:**  
  - **Datasets:**  
    - [Open Trivia DB](https://opentdb.com/)
    - [Quiz Questions Dataset (Kaggle)](https://www.kaggle.com/datasets/abhinavmoudgil95/short-questions)
  - **Training Process:**  
    - Used to fine-tune or prompt GenAI for quiz creation and evaluation.

---

## Project Structure

```text
MAP-NATION/
│
├── server/
│   ├── controllers/      # API logic (AI, quiz, roadmap, progress)
│   ├── Models/           # Database models (User, Roadmap, Quiz, Progress)
│   ├── Routes/           # API endpoints
│   ├── services/         # AI/GenAI integration logic
│   ├── utils/            # Helper functions, API wrappers
│   ├── Middleware/       # Auth, validation, etc.
│   └── server.js         # Node.js entry point
│
├── src/
│   ├── components/       # React UI components (Dashboard, Profile, etc.)
│   ├── App.jsx           # Main React app
│   └── main.jsx          # React entry point
│
├── public/               # Static files (images, videos)
├── README.md             # Project documentation
├── package.json          # Node.js dependencies
├── server/requirements.txt# Python dependencies (if any)
```

---

## How to Set Up & Run

### 1. Clone the Repo

```bash
git clone https://github.com/yourusername/map-nation.git
cd MAP-NATION
```

### 2. Install Node.js Dependencies

```bash
cd server
npm install
```

### 3. (Optional) Install Python Dependencies

```bash
cd ai
python -m venv venv
# On Windows:
venv\Scripts\activate
# On Mac/Linux:
source venv/bin/activate

pip install -r requirements.txt
```

### 4. Start the Backend Server

```bash
# For Node.js backend (APIs, GenAI integration, etc.)
node server.js
```

### 5. Start the Frontend

```bash
cd ../
npm install
npm run dev
```

### 6. (Optional) Deploy with Nginx Load Balancer

- Use **Nginx** to distribute traffic across multiple backend instances for high availability and fast response.

#### Example: Simple Nginx Load Balancer Setup

1. **Install Nginx** (Linux example):
   ```bash
   sudo apt update
   sudo apt install nginx
   ```
2. **Edit Nginx config** (e.g., `/etc/nginx/nginx.conf`):
   ```nginx
   http {
       upstream mapnation_backend {
           server 127.0.0.1:3000;
           server 127.0.0.1:3001;
           # Add more backend servers as needed
       }

       server {
           listen 80;
           location / {
               proxy_pass http://mapnation_backend;
               proxy_set_header Host $host;
               proxy_set_header X-Real-IP $remote_addr;
           }
       }
   }
   ```
3. **Restart Nginx:**
   ```bash
   sudo systemctl restart nginx
   ```

---

## Datasets Used

- **Learning Roadmaps:** [Open Syllabus Project](https://opensyllabus.org/), [Curriculum Dataset (Kaggle)](https://www.kaggle.com/datasets/andrewmvd/curriculum-dataset)
- **Quiz Generation:** [Open Trivia DB](https://opentdb.com/), [Quiz Questions Dataset (Kaggle)](https://www.kaggle.com/datasets/abhinavmoudgil95/short-questions)

---

## Need Help?

- Check code comments for more details.
- For model/data questions, see the `server/ai/` and `server/services/` folders.
- For API usage, see the `server/Routes/` and `server/controllers/` folders.

---

## Scaling the System

To ensure MAP-NATION can handle high traffic and many users at once, the system supports horizontal scaling using multiple backend instances and Nginx load balancing.

### 1. Running Multiple Backend Instances

```bash
node server.js --port=3000
node server.js --port=3001
# ...add more as needed
```
Similarly, run multiple Python AI service instances for heavy processing.

### 2. Nginx Load Balancer

Use Nginx as a load balancer. List all backend servers in the `upstream` block. Nginx automatically distributes incoming requests to all available servers.

### 3. Scaling Python AI Services

For AI-heavy tasks, run multiple Python (main.py) instances. Node.js can send requests to any available Python worker, distributing the load.

### 4. (Optional) Docker & Kubernetes

For even easier scaling and deployment, use Docker Compose or Kubernetes. This lets you spin up as many containers as needed, and manage them efficiently.

### 5. Database Scaling

Run MongoDB in replica set or sharded mode for high availability and performance.

### 6. Monitoring & Auto-Scaling

Use tools like PM2, Docker Swarm, or Kubernetes HPA for process management and auto-scaling. For monitoring, Grafana and Prometheus help track system health and performance.

---

## Example: Local Scaling with Nginx

```bash
# Start 2-3 Node.js servers (e.g., on ports 3000, 3001, 3002)
node server.js --port=3000
node server.js --port=3001
node server.js --port=3002
```

```nginx
# Add all server addresses to the Nginx config (nginx.conf)
http {
    upstream mapnation_backend {
        server 127.0.0.1:3000;
        server 127.0.0.1:3001;
        server 127.0.0.1:3002;
    }

    server {
        listen 80;
        location / {
            proxy_pass http://mapnation_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
}
```

```bash
# Restart Nginx
sudo systemctl restart nginx
```

Nginx will distribute all incoming requests across your backend servers automatically.

---

## Scaling Summary Table

| Step                | Tool/Tech         | Purpose                        |
|---------------------|------------------|--------------------------------|
| Multiple servers    | Node.js, Python  | Handle more requests           |
| Load balancing      | Nginx            | Distribute traffic             |
| Containerization    | Docker/K8s       | Easy deployment & scaling      |
| DB scaling          | MongoDB Replica  | High availability, no bottlenecks |


---

This approach keeps MAP-NATION fast, reliable, and ready for growth.  